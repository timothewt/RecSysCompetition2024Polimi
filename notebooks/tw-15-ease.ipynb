{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "V28"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "TPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gB0lHZghvR-p"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "\n",
    "from src.hyperparameters_optimizer import HyperparametersOptimizer\n",
    "from src.recommender_model import RecommenderModel\n",
    "from src.utils import train_model, write_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EASE$^{\\text{R}}$\n",
    "This notebook provides an implementation of the EASE$^{\\text{R}}$ model. See [Embarrassingly Shallow Autoencoders for Sparse Data, Harald Steck](https://arxiv.org/pdf/1905.03375)."
   ],
   "metadata": {
    "id": "464SSm3S0Fq1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class EASER(RecommenderModel):\n",
    "\t\"\"\"\n",
    "\tImportant note:\n",
    "\t\tOn this dataset with a URM about the size of (35000,40000), this needs at least 60GB of RAM.\n",
    "\t\tRun on g-colab TPUs to get 300+GB of RAM.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(EASER, self).__init__()\n",
    "\t\tself.lambda_reg: float = 0\n",
    "\n",
    "\tdef fit(self, urm: sp.csr_matrix, lambda_reg: float = 200, **kwargs) -> None:\n",
    "\t\tself.urm = urm.astype(np.float32)\n",
    "\t\tself.lambda_reg = lambda_reg\n",
    "\n",
    "\t\tg = (self.urm.T @ self.urm)\n",
    "\t\tg += sp.identity(g.shape[0], dtype=np.float32) * self.lambda_reg\n",
    "\t\tg = g.toarray().astype(np.float32)\n",
    "\t\tp = np.linalg.inv(g)\n",
    "\t\tb = p / (-np.diag(p))\n",
    "\t\tnp.fill_diagonal(b, 0.)\n",
    "\n",
    "\t\tself.urm_pred = self.urm @ b"
   ],
   "metadata": {
    "id": "AO_SE6O8v3Yh"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = HyperparametersOptimizer({\n",
    "\t'lambda_reg': [40, 45, 50, 55, 60],\n",
    "}, EASER)\n",
    "_, best_parameters = optimizer.optimize()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITVaHh0lyMPl",
    "outputId": "64449176-3a77-4c4f-c6d5-2f1dea48d25a"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5/5 [18:46<00:00, 225.26s/it, Best MAP@10: 0.0776 with ['lambda_reg: 4.50e+01']]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "ease_r_submission, _ = train_model(EASER(), test_size=0, **best_parameters)\n",
    "write_submission(ease_r_submission, \"ease_r_submission.csv\")"
   ],
   "metadata": {
    "id": "6xpaHdzEv5Un"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Submission result: `0.08950`",
   "metadata": {
    "id": "c9pBr1AI1G-d"
   }
  }
 ]
}
