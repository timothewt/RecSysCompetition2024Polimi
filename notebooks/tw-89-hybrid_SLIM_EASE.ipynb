{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "V28"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "TPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip -q install fast_map"
   ],
   "metadata": {
    "id": "r7Ync6H0agFO"
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "gEhLT3gcaLA2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from fast_map import fast_map\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class RecommenderModel:\n",
    "    def __init__(self):\n",
    "        self.urm: sp.csr_matrix | None = None\n",
    "        self.icm: sp.csr_matrix | None = None\n",
    "        self.urm_pred: sp.csr_matrix | None = None\n",
    "\n",
    "    def fit(self, urm: sp.csr_matrix, icm: sp.csr_matrix, urm_val: sp.csr_matrix, progress_bar: bool = True, **kwargs) -> None:\n",
    "        \"\"\"Fits (trains) the model on the given URM and (or) ICM, depending on the algorithm. To be overridden in\n",
    "        subclasses.\n",
    "\n",
    "        :param urm: User Ratings Matrix for training\n",
    "        :type urm: sp.csr_matrix\n",
    "        :param icm: Item Content Matrix\n",
    "        :type icm: sp.csr_matrix\n",
    "        :param urm_val: User Ratings Matrix for validation\n",
    "        :type urm_val: sp.csr_matrix\n",
    "        :param progress_bar: If true, progress bar will be shown (if implemented if subclass)\n",
    "        :type progress_bar: bool\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def recommend(self, user_id: int, at: int = 10) -> np.ndarray:\n",
    "        \"\"\"Gives the top {at} recommended items for this user.\n",
    "\n",
    "        :param user_id: ID of the user to recommend to\n",
    "        :type user_id: int\n",
    "        :param at: Number of items to recommend\n",
    "        :type at: int\n",
    "        :return: The {at} most relevant recommended items\n",
    "        :rtype: np.ndarray\n",
    "        \"\"\"\n",
    "        recommendations_predictions = self._get_recommendations_predictions(user_id).astype(np.float32)\n",
    "        self._exclude_seen_items(user_id, recommendations_predictions)\n",
    "\n",
    "        top_n_ratings_idx = np.argpartition(-recommendations_predictions, at)[:at]\n",
    "        top_n_ratings = recommendations_predictions[top_n_ratings_idx]\n",
    "\n",
    "        return top_n_ratings_idx[\n",
    "            np.argsort(-top_n_ratings)\n",
    "        ]\n",
    "\n",
    "    def _get_recommendations_predictions(self, user_id: int) -> np.ndarray:\n",
    "        \"\"\"Gives the recommendations predictions for a given user, which are the probabilities or top-n (the higher,\n",
    "        the better) that the items should be recommended to the user. It should be overridden in some subclasses\n",
    "\n",
    "        :param user_id: ID of the user to recommend to\n",
    "        :type user_id: int\n",
    "        :return: The recommendations predictions for all the items of the urm\n",
    "        :rtype: np.ndarray\n",
    "        \"\"\"\n",
    "        if isinstance(self.urm_pred, sp.spmatrix):\n",
    "            return self.urm_pred[user_id].toarray().ravel()\n",
    "        elif isinstance(self.urm_pred, np.ndarray):\n",
    "            return self.urm_pred[user_id]\n",
    "        else:\n",
    "            raise \"Unknown type of urm predictions\"\n",
    "\n",
    "    def _exclude_seen_items(self, user_id: int, predicted_ratings: np.ndarray) -> None:\n",
    "        \"\"\"Excludes the items the user has already seen in the predicted ratings list. In-place operation!\n",
    "\n",
    "        :param user_id: The id of the user\n",
    "        :type user_id: int\n",
    "        :param predicted_ratings: The predicted ratings of items for a user\n",
    "        :type predicted_ratings: np.ndarray\n",
    "        \"\"\"\n",
    "        seen_items = self.urm.indices[self.urm.indptr[user_id]:self.urm.indptr[user_id + 1]]\n",
    "        predicted_ratings[seen_items] = -np.inf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def open_dataset() -> tuple[sp.csr_matrix, sp.csr_matrix]:\n",
    "\t\"\"\"Opens the dataset (URM and ICM matrices) into sparse matrices\n",
    "\n",
    "\t:return: The URM and ICM as sparse matrices\n",
    "\t:rtype: tuple[sp.csr_matrix, sp.csr_matrix]\n",
    "\t\"\"\"\n",
    "\ttrain = pd.read_csv(\"./data_train.csv\")\n",
    "\ticm_metadata = pd.read_csv(\"./data_ICM_metadata.csv\")\n",
    "\turm = sp.csr_matrix((train['data'], (train['user_id'], train['item_id']))).astype(np.float32)\n",
    "\ticm = sp.csr_matrix((icm_metadata['data'], (icm_metadata['item_id'], icm_metadata['feature_id']))).astype(np.float32)\n",
    "\treturn urm, icm\n",
    "\n",
    "\n",
    "def train_test_split(urm: sp.csr_matrix, test_size: float = .2) -> tuple[sp.csr_matrix, sp.csr_matrix]:\n",
    "\t\"\"\"Splits the URM matrix into a train and test dataset over the users.\n",
    "\n",
    "\t:param urm: The User-Rating matrix\n",
    "\t:type urm: sp.csr_matrix\n",
    "\t:param test_size: The test size (in [0,1])\n",
    "\t:type test_size: float\n",
    "\t:return: The train and test URM matrices\n",
    "\t:rtype: tuple[sp.csr_matrix, sp.csr_matrix]\n",
    "\t\"\"\"\n",
    "\ttrain_mask = np.random.choice([True, False], urm.getnnz(), p=[1 - test_size, test_size])\n",
    "\ttest_mask = ~train_mask\n",
    "\n",
    "\turm_coo = urm.tocoo()\n",
    "\turm_train = sp.csr_matrix((urm_coo.data[train_mask], (urm_coo.row[train_mask], urm_coo.col[train_mask])))\n",
    "\tif test_size > 0:\n",
    "\t\turm_test = sp.csr_matrix((urm_coo.data[test_mask], (urm_coo.row[test_mask], urm_coo.col[test_mask])))\n",
    "\telse:\n",
    "\t\turm_test = sp.csr_matrix([])\n",
    "\n",
    "\treturn urm_train, urm_test\n",
    "\n",
    "\n",
    "def average_precision(recommendations: np.ndarray, y: np.ndarray, k: int = 10) -> float:\n",
    "\t\"\"\"Computes the Average Precision of a recommendation\n",
    "\n",
    "\t:param recommendations: Recommendations for a user\n",
    "\t:type recommendations: np.ndarray\n",
    "\t:param y: Ground truth array of relevant items to be recommended\n",
    "\t:type y: np.ndarray\n",
    "\t:param k: Number of items to consider (AP@k)\n",
    "\t:type k: int\n",
    "\t:return: The Average Precision at k for these particular recommendations\n",
    "\t:rtype: float\n",
    "    \"\"\"\n",
    "\trelevance_mask = np.isin(recommendations[:k], y)\n",
    "\tprecisions = np.cumsum(relevance_mask) / (np.arange(1, k+1))\n",
    "\treturn np.sum(precisions * relevance_mask) / min(len(y), k) if len(y) > 0 else 0.\n",
    "\n",
    "\n",
    "def evaluate_model(trained_model: RecommenderModel, urm_test: sp.csr_matrix, at: int = 10, users_to_test: float = 1.) -> float:\n",
    "\t\"\"\"Evaluates a recommender model using the MAP metric\n",
    "\n",
    "\t:param trained_model: A fitted recommender model\n",
    "\t:type trained_model: RecommenderModel\n",
    "\t:param urm_test: The test URM matrix\n",
    "\t:type urm_test: sp.csr_matrix\n",
    "\t:param at: The number of items to recommend to each user\n",
    "\t:type at: int\n",
    "\t:param users_to_test: The ratio of users to test (in [0,1])\n",
    "\t:type users_to_test: float\n",
    "\t:return: The MAP metric for this model on this test data\n",
    "\t:rtype: float\n",
    "\t\"\"\"\n",
    "\tcum_ap = 0.\n",
    "\teval_count = 0\n",
    "\n",
    "\tnum_users = urm_test.shape[0]\n",
    "\tusers_ids = np.arange(num_users) if users_to_test == 1 else np.random.choice(num_users, size=int(users_to_test * num_users))\n",
    "\n",
    "\tfor user_id in users_ids:\n",
    "\t\ty = urm_test.indices[urm_test.indptr[user_id]:urm_test.indptr[user_id+1]]\n",
    "\t\tif len(y) > 0:\n",
    "\t\t\teval_count += 1\n",
    "\t\t\trecommendations = trained_model.recommend(user_id, at=at)\n",
    "\t\t\tcum_ap += average_precision(recommendations, y, k=at)\n",
    "\n",
    "\treturn (cum_ap / eval_count).item()\n",
    "\n",
    "\n",
    "def train_model(model: RecommenderModel, at: int = 10, test_size: float = .2, users_to_test: float = 1, print_eval: bool = True, **kwargs) -> tuple[RecommenderModel, float]:\n",
    "\t\"\"\"Given a recommender model, trains it and evaluates it on test data, then returns the trained model.\n",
    "\n",
    "\t:param model: The model to train, an instance of a recommender model\n",
    "\t:type model: RecommenderModel\n",
    "\t:param at: The number of recommendations given to each user\n",
    "\t:type at: int\n",
    "\t:param test_size: The test size (in [0,1]) for the train/test split. If set to zero, the model uses the whole\n",
    "\tdataset to train and is not evaluated\n",
    "\t:type test_size: float\n",
    "\t:param users_to_test:\n",
    "\t:param print_eval: Indicates if the function should print the model evaluation after training\n",
    "\t:type print_eval: bool\n",
    "\t:return: The fitted (trained) recommender model and the MAP@10 score\n",
    "\t:rtype: tuple[RecommenderModel, float]\n",
    "\t\"\"\"\n",
    "\turm, icm = open_dataset()\n",
    "\turm_train, urm_test = train_test_split(urm, test_size=test_size)\n",
    "\n",
    "\tmodel.fit(urm=urm_train, icm=icm, urm_val=urm_test, **kwargs)\n",
    "\n",
    "\tmap_10 = 0\n",
    "\tif print_eval and test_size > 0:\n",
    "\t\tmap_10 = evaluate_model(model, urm_test, at=at, users_to_test=users_to_test)\n",
    "\t\tprint(f\"MAP@{at} evaluation of the {model.__class__.__name__} model: {map_10:.5f}\")\n",
    "\n",
    "\treturn model, map_10\n",
    "\n",
    "\n",
    "def write_submission(trained_model: RecommenderModel, filename: str = \"submission.csv\", at: int = 10) -> None:\n",
    "\t\"\"\"Builds the submission file from a trained recommender model. The file is saved in a CSV format.\n",
    "\n",
    "\t:param trained_model: A fitted recommender model\n",
    "\t:type trained_model: RecommenderModel\n",
    "\t:param filename: The filename of the submission for this particular recommender model\n",
    "\t:type filename: str\n",
    "\t:param at: Number of items to recommend\n",
    "\t:type at: int\n",
    "\t\"\"\"\n",
    "\ttarget_users_test = pd.read_csv(\"./data_target_users_test.csv\",).to_numpy().ravel()\n",
    "\n",
    "\trecommendations = np.array([\n",
    "\t\ttrained_model.recommend(user_id, at) for user_id in target_users_test\n",
    "\t])\n",
    "\n",
    "\tif not os.path.exists(\"../submissions\"):\n",
    "\t\tos.makedirs(\"../submissions\")\n",
    "\twith open(f\"../submissions/{filename}\", \"w\") as f:\n",
    "\t\tf.write(\"user_id,item_list\\n\")\n",
    "\t\tfor user_id, recs in zip(target_users_test, recommendations):\n",
    "\t\t\tf.write(f\"{user_id},{' '.join(map(str, recs))}\\n\")\n",
    "\n",
    "\n",
    "def tf_idf(mat: sp.csr_matrix) -> sp.csr_matrix:\n",
    "\t\"\"\"Rescales the matrix values by weighting the features of the matrix (typically the ICM) using TF-IDF\n",
    "\n",
    "\t:param mat: The sparse matrix\n",
    "\t:type mat: sp.csr_matrix\n",
    "\t:return: The matrix rescaled by TF-IDF\n",
    "\t:rtype: sp.csr_matrix\n",
    "\t\"\"\"\n",
    "\tmat = mat.copy()\n",
    "\tdf = np.asarray(mat.sum(axis=0)).ravel()\n",
    "\tidf = np.log(mat.shape[0] / (df + 1))\n",
    "\tmat.data = mat.data * idf[mat.tocoo().col]\n",
    "\tmat.eliminate_zeros()\n",
    "\treturn mat\n",
    "\n",
    "\n",
    "def plot_losses(epochs: int, loss_history: np.ndarray | list, loss_history_val: np.ndarray | list = None, num_batch_per_epochs: int = 1, other_data: tuple = None) -> None:\n",
    "\t\"\"\"Plots the losses history of a training.\n",
    "\n",
    "\t:param epochs: The number of epochs\n",
    "\t:type epochs: int\n",
    "\t:param loss_history: The loss history\n",
    "\t:type loss_history: np.ndarray | list\n",
    "\t:param loss_history_val: The validation loss history\n",
    "\t:type loss_history_val: np.ndarray | list\n",
    "\t:param num_batch_per_epochs: The number of batches per epoch\n",
    "\t:type num_batch_per_epochs: int\n",
    "\t:param other_data: Other data to plot (optional). The format is (label: str, x: list, y: list)\n",
    "\t:type other_data: tuple\n",
    "\t\"\"\"\n",
    "\tplt.plot(loss_history, label=\"Train loss\")\n",
    "\tif loss_history_val is not None:\n",
    "\t\tplt.plot([x * num_batch_per_epochs for x in range(epochs + 1)], loss_history_val, label=\"Validation loss\")\n",
    "\tplt.xlabel(\"Train iteration\")\n",
    "\tplt.ylabel(\"Loss\")\n",
    "\tplt.title(\"Loss history\")\n",
    "\tplt.legend(loc=\"upper right\")\n",
    "\tif other_data:\n",
    "\t\tlabel, x, y = other_data\n",
    "\t\tax2 = plt.gca().twinx()\n",
    "\t\tax2.plot(x, y, label=label, c=\"C2\")\n",
    "\t\tplt.legend(loc=\"lower left\")\n",
    "\n",
    "\tplt.grid(True)\n",
    "\tplt.show()\n",
    "\n",
    "class EASER(RecommenderModel):\n",
    "    \"\"\"\n",
    "    Important note:\n",
    "        On this dataset with a URM about the size of (35000,40000), this needs at least 60GB of RAM.\n",
    "        Run on g-colab TPUs to get 300+GB of RAM.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(EASER, self).__init__()\n",
    "        self.lambda_reg: float = 0\n",
    "\n",
    "    def fit(self, urm: sp.csr_matrix, lambda_reg: float = 45, **kwargs) -> None:\n",
    "        self.urm = urm.astype(np.float32)\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "        g = (self.urm.T @ self.urm)\n",
    "        g += sp.identity(g.shape[0], dtype=np.float32) * self.lambda_reg\n",
    "        g = g.toarray().astype(np.float32)\n",
    "        p = np.linalg.inv(g)\n",
    "        b = p / (-np.diag(p))\n",
    "        np.fill_diagonal(b, 0.)\n",
    "\n",
    "        self.urm_pred = self.urm @ b\n",
    "\n",
    "class SLIMElasticNet(RecommenderModel):\n",
    "    def __init__(self):\n",
    "        super(SLIMElasticNet, self).__init__()\n",
    "        self.alpha: float = 0\n",
    "        self.l1_ratio: float = 0\n",
    "        self.top_k: int = 0\n",
    "        self.max_iter: int = 0\n",
    "        self.similarity_matrix: sp.csr_matrix | None = None\n",
    "\n",
    "    @staticmethod\n",
    "    def process_item(item_idx: int, urm_csc: sp.csc_matrix, top_k: int, alpha: float, l1_ratio: float, max_iter: int):\n",
    "        elastic_net = ElasticNet(\n",
    "            alpha=alpha,\n",
    "            l1_ratio=l1_ratio,\n",
    "            fit_intercept=False,\n",
    "            positive=True,\n",
    "            copy_X=False,\n",
    "            selection='random',\n",
    "            max_iter=max_iter,\n",
    "            tol=1e-3\n",
    "        )\n",
    "\n",
    "        y = urm_csc[:, item_idx].toarray()\n",
    "        x = urm_csc.copy()\n",
    "        x.data[x.indptr[item_idx]:x.indptr[item_idx + 1]] = 0.\n",
    "\n",
    "        elastic_net.fit(urm_csc, y)\n",
    "\n",
    "        coeffs_idxs = elastic_net.sparse_coef_.indices\n",
    "        coeffs_vals = elastic_net.sparse_coef_.data\n",
    "\n",
    "        if coeffs_idxs.shape[0] > top_k:\n",
    "            relevant_items = np.argpartition(-np.abs(coeffs_vals), top_k)[:top_k]\n",
    "            coeffs_idxs = coeffs_idxs[relevant_items]\n",
    "            coeffs_vals = coeffs_vals[relevant_items]\n",
    "\n",
    "        return item_idx, coeffs_idxs, coeffs_vals\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        urm: sp.csr_matrix,\n",
    "        progress_bar: bool = True,\n",
    "        top_k: int = 300,\n",
    "        l1_reg: float = 1e-7,\n",
    "        l2_reg: float = 1e-5,\n",
    "        max_iter: int = 100,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        self.urm = urm\n",
    "        urm_csc = self.urm.tocsc()\n",
    "        num_items = self.urm.shape[1]\n",
    "\n",
    "        self.top_k = min(top_k, num_items - 1)\n",
    "        self.alpha = l1_reg + l2_reg\n",
    "        self.l1_ratio = l1_reg / self.alpha\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        s_rows = []\n",
    "        s_cols = []\n",
    "        s_vals = []\n",
    "\n",
    "        mapper = fast_map(self.process_item, range(num_items), [urm_csc] * num_items, [self.top_k] * num_items, [self.alpha] * num_items, [self.l1_ratio] * num_items, [self.max_iter] * num_items, threads_limit=10)\n",
    "        iterator = tqdm(mapper, desc=\"Items\", total=num_items) if progress_bar else mapper\n",
    "\n",
    "        for item_idx, coeffs_idxs, coeffs_vals in iterator:\n",
    "            s_rows.extend([item_idx] * len(coeffs_idxs))\n",
    "            s_cols.extend(coeffs_idxs)\n",
    "            s_vals.extend(coeffs_vals)\n",
    "\n",
    "        self.similarity_matrix = sp.csr_matrix(\n",
    "            (s_vals, (s_rows, s_cols)),\n",
    "            shape=(num_items, num_items),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.urm_pred = self.urm @ self.similarity_matrix\n",
    "\n",
    "\n",
    "class HybridSLIMEASE(RecommenderModel):\n",
    "    def __init__(self):\n",
    "        super(HybridSLIMEASE, self).__init__()\n",
    "        self.slim = None\n",
    "        self.ease = None\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        urm: sp.csr_matrix,\n",
    "        slim_ratio,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        self.urm = urm\n",
    "        self.slim_ratio = slim_ratio\n",
    "\n",
    "        self.slim = SLIMElasticNet()\n",
    "        self.slim.fit(urm, **kwargs)\n",
    "\n",
    "        self.ease = EASER()\n",
    "        self.ease.fit(urm, **kwargs)\n",
    "\n",
    "    def _get_recommendations_predictions(self, user_id: int) -> np.ndarray:\n",
    "        return self.slim_ratio * self.slim.urm_pred[user_id] + (1 - self.slim_ratio) * self.ease.urm_pred[user_id]"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "urm, icm = open_dataset()\n",
    "urm_train, urm_test = train_test_split(urm, test_size=.2)"
   ],
   "metadata": {
    "id": "xatAvrlBcRtR"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = HybridSLIMEASE()\n",
    "model.fit(urm_train, slim_ratio=0.5, urm_val=urm_test, icm=icm)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CI_4Gkgqcx7d",
    "outputId": "a3a91fe8-b889-4ae2-f3a1-04a033dfd55c"
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Items: 100%|██████████| 38121/38121 [09:31<00:00, 66.70it/s] \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for slim_ratio in np.arange(0, 1.1, .1):\n",
    "    print(f\"{slim_ratio=}: MAP@10={evaluate_model(model, urm_test, at=10, users_to_test=1)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "id": "MoRC1cctdKnq",
    "outputId": "720e0d3c-7bc8-4bbc-fff9-f7878966e986"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 120 is out of bounds for axis 0 with size 1",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-29-0f3a95c6aca8>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0malpha\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1.1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m.1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"{alpha=}: MAP@10={evaluate_model(model, urm_test, at=10, users_to_test=1)}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-25-a2590dffd1d7>\u001B[0m in \u001B[0;36mevaluate_model\u001B[0;34m(trained_model, urm_test, at, users_to_test)\u001B[0m\n\u001B[1;32m    158\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    159\u001B[0m                         \u001B[0meval_count\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 160\u001B[0;31m                         \u001B[0mrecommendations\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrained_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecommend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muser_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mat\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    161\u001B[0m                         \u001B[0mcum_ap\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0maverage_precision\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecommendations\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-25-a2590dffd1d7>\u001B[0m in \u001B[0;36mrecommend\u001B[0;34m(self, user_id, at)\u001B[0m\n\u001B[1;32m     42\u001B[0m         \"\"\"\n\u001B[1;32m     43\u001B[0m         \u001B[0mrecommendations_predictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_recommendations_predictions\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muser_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exclude_seen_items\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muser_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecommendations_predictions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m         \u001B[0mtop_n_ratings_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margpartition\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mrecommendations_predictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mat\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-25-a2590dffd1d7>\u001B[0m in \u001B[0;36m_exclude_seen_items\u001B[0;34m(self, user_id, predicted_ratings)\u001B[0m\n\u001B[1;32m     76\u001B[0m         \"\"\"\n\u001B[1;32m     77\u001B[0m         \u001B[0mseen_items\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindices\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindptr\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0muser_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindptr\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0muser_id\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 78\u001B[0;31m         \u001B[0mpredicted_ratings\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mseen_items\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     79\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: index 120 is out of bounds for axis 0 with size 1"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class TestModel(RecommenderModel):\n",
    "    def __init__(self, slim, ease, urm):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.slim = slim\n",
    "        self.ease = ease\n",
    "        self.slim_ratio = .5\n",
    "        self.urm=urm\n",
    "    def _get_recommendations_predictions(self, user_id: int) -> np.ndarray:\n",
    "        return self.slim_ratio * self.slim.urm_pred[user_id].toarray().ravel() + (1 - self.slim_ratio) * self.ease.urm_pred[user_id]"
   ],
   "metadata": {
    "id": "tWnp0RU_kNGD"
   },
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "m = TestModel(model.slim, model.ease, urm_train)"
   ],
   "metadata": {
    "id": "tJs9zvGblJB4"
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for slim_ratio in np.arange(0, 1.1, .1):\n",
    "    m.slim_ratio = slim_ratio\n",
    "    print(f\"{slim_ratio=}: MAP@10={evaluate_model(m, urm_test, at=10, users_to_test=1)}\")"
   ],
   "metadata": {
    "id": "Wfe6PHhQlZk4",
    "outputId": "ba905f42-a20f-4929-be20-f9d7dddb426b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 61,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "slim_ratio=0.0: MAP@10=0.07768906611989392\n",
      "slim_ratio=0.1: MAP@10=0.07782439251224023\n",
      "slim_ratio=0.2: MAP@10=0.07801684533026695\n",
      "slim_ratio=0.30000000000000004: MAP@10=0.07824286867179803\n",
      "slim_ratio=0.4: MAP@10=0.07858456928336222\n",
      "slim_ratio=0.5: MAP@10=0.079050506661552\n",
      "slim_ratio=0.6000000000000001: MAP@10=0.0795870275702205\n",
      "slim_ratio=0.7000000000000001: MAP@10=0.08043719500680566\n",
      "slim_ratio=0.8: MAP@10=0.08147913004163017\n",
      "slim_ratio=0.9: MAP@10=0.08174388818746725\n",
      "slim_ratio=1.0: MAP@10=0.04123829385797967\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "m.slim_ratio = .6\n",
    "write_submission(m)"
   ],
   "metadata": {
    "id": "31anZh-6l1uS"
   },
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "OPbREX3BoMu_"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
