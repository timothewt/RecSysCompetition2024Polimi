<h1 align="center">Recommender System 2024-2025 Challenge - Polimi</h1>


<p align="center" style="background-color: white; padding: 10px;">
  <img src="images/polimi.png" alt="Polimi Image" />
</p>

[Link to competition](https://www.kaggle.com/competitions/recommender-system-2024-challenge-polimi/overview)


## Results
Evaluated (final results, ensemble of three models):
* MAP@10 - private: 0.10128
* MAP@10 - public: **0.10286**
* Ranked **13nd**

Best metrics (were missed, XGBoost):
* MAP@10 - private: **0.10170**
* MAP@10 - public: 0.10271


## Application domain & Goal
The application domain is book recommendation. The provided datasets contains interactions of users with books.
The main goal of the competition is to discover which new books a user will interact with. We had to recommend a list of 10 potentially relevant new items for each user.

## Evaluation

For evaluation, the MAP@10 metric was used.

The average precision at 10, for a user is defined as:

$$
AP@10 = \frac{\sum_{k=1}^{10} P(k) \cdot \text{rel}(k)}{\min(m, 10)}
$$

Where:
- $P(k)$ is the precision at cut-off $k$,
- $\text{rel}(k)$ is 1 if the item at position $k$ is relevant, and 0 otherwise,
- $m$ is the number of relevant items in the test set.

The mean average precision for $N$ users at position 10 is the average of the average precision of each user:

$$
MAP@10 = \frac{\sum_{u=1}^{N} AP@10_u}{N}
$$


## Dataset
The datasets includes around 1.9 M interactions, 35k users, 38k items (books) as well as 94k item features.
The training-test split is done via random holdout, 80% training, 20% test.

## Best solution
Our best public solution was weighted ensemble of three algorithms:
* SLIM ElasticNet
* RP3Beta
* ItemKNNCFRecommender

Our best private solution was xgboost, which used as features:
* Candidates, generated by ensemble of three previous models, trained on $\textbf{Recall}$
* Item score of SLIM ElasticNet
* Item score of RP3Beta
* Item score of ItemKNNCFRecommender
* Item Popularity
* User profile len
* 10 most common features from items (ICM matrix)

## What Worked  
1. Based on solutions from previous years, the **SLIM** and **RP3** models consistently delivered good results, so they became our main models.  
2. [Optuna](https://optuna.readthedocs.io/en/stable/): This library helped us find the best hyperparameters. Initially, we used a simple grid search, which significantly narrowed down the optimal solution space, but the final tuning was done with Optuna.  
3. **Ensemble of the three best models**: Initially, the ensemble performed worse than a single **SLIM** model. However, after optimizing the other two models, the ensemble became the best-performing approach.  

## What Did Not Work  
1. **Complex algorithms** (*Matrix Factorization, SSLIM, EASER, IALS*) — all of these required enormous computational resources and long runtimes for hyperparameter tuning. Despite this, they produced some of the worst results.  
2. **SVD-based models**: Their performance was worse compared to other algorithms, so they were not included in the final solution.  

## What We Didn't Try  
1. Running everything on **Kaggle** or any other platform with **GPUs**.  
2. **Cross-validation**: Training **SLIM** took around **20 minutes**, so we decided not to search for the best hyperparameters using cross-validation. Unfortunately, this led to overfitting, and we failed to realize that our best model was actually **XGBoost**.  

## Our References
* [RecSys Course @ Politecnico di Milano](https://github.com/recsyspolimi/RecSys_Course_AT_PoliMi)
* [Recommender System Challenge 2023/2024 Polimi](https://github.com/FrancescoZanella/RecSystems)
* [Recommender Systems 2020 Challenge](https://github.com/Alexdruso/recsys-challenge-2020-polimi)

## Advanced Theory Exam
In addition we provide file, with summary of all...

## Team
* Iusupov Safuan [Telegram](https://t.me/IusupovSafuan) | [GitHub](https://github.com/SAFUANlip) | safuan.iusupov@mail.polimi.it
* [Timothé Watteau](https://t.me/TheirTelegramUsername) | [GitHub](https://github.com/TheirGitHubUsername) | [Email](mailto:their.email@example.com)

